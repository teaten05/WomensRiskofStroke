# Womens Risk of Stroke
Intro to Machine learning project in collaboration with professor Dr. Egawati Panjei at SMU Lyle School of Engineering.

## Abstract
This study examines the gender-specific relationship between anxious-related attributes and stroke risk using multiple machine-learning approaches. Which shows comprehensive models tuned through hyperparameter optimization in pipelines by implementing Random Forest Regressor for stroke risk percentage prediction and Logistic Regression for binary risk classification. Contrary to the initial hypothesis, the analysis revealed that anxiety appears to have a stronger association with stroke risk in men compared to women. However, this finding warrants careful interpretation as the gender-stratified models demonstrated significantly higher performance metrics for women, with better accuracy and substantially lower Mean Squared Error values. So, this performance disparity suggests potential limitations in model reliability when applied to male subjects and highlights the need for further investigation. These findings demonstrate the value of employing multiple algorithms for stroke risk analysis while emphasizing the importance of critically evaluating model performance concerning demographic groups. These findings contribute to the development of more nuanced stroke risk assessment protocols and underscore the complex interplay between psychological factors and cardiovascular health across genders.

## About Dataset
In total, 7 attributes were used for the female datasets, while only 3 attributes were used for the male datasets, with 35,000 data points. These attributes include the integer age, which describes the age of the person aged 20-85. The integer high blood pressure is a discrete value used to classify whether the patient has high blood pressure (1) or not (0). The integer irregular heartbeat is another discrete value to classify whether the patient has an irregular heartbeat (1) or not (0). The integer fatigue/weakness is a discrete value to classify whether the patient is experiencing fatigue or weakness (1) or not (0). Additionally, the integer anxiety/doom is a discrete value used to classify whether the patient has anxiety or feelings of doom (1) or not (0). Then, the target variables used for the models are stroke risk percentage and at-risk. The stroke risk percentage is a float from 0-100%, which describes the patient's percentage chance of having a stroke, given all of the systems and their age at the time of inspection. At risk is an integer that uses discrete values to classify the patient as at risk (1) or not (0).

Some interesting outliers and patterns in this dataset can be seen below with histograms and box plots of all attributes. Some of the most significant outliers are in the Distribution of Stroke Risk Percentage. On the graph, the stroke risk percentage compared to the count slowly declines as the percentage increases. However, there is a massive spike in the count at 95-100%, which may signal initial problems with the dataset. Other outliers that describe the data set are in the Boxplot of Age. This boxplot shows that most data points are people 18-70 years old, and very few patients are older than that.
Furthermore, an interesting pattern in the data exploration period, which can also be seen from the pipeline results, is a pattern between irregular heartbeat and high blood pressure. Both have similar box plots and predictions. Another interesting pattern is one between fatigue/weakness and anxiety/doom. When comparing them to stroke risk percentage on the box plots and the pipeline results, these two attributes also have nearly the same distribution.

## About the Machine Learning Models
For the classification task of predicting whether a person is at risk, a Logistic Regression model was used, one for each gender. This model is the best option for this task for both women's and men's data points because of its strong performance in binary classification. It is also important to use a model like this because the results of predictor models using Logistic Regression are easily interpretable. The model was imported from scikit-learn.

The processes of hyperparameter tuning included using a pipeline implementing Logistic Regression, Principal Component Analysis, and Standardization using StandardScaler. The tuning was done using grid search cross-validation with a cv equal to 10, and the hyperparameters were based on accuracy. The parameters tested in this process were C range, penalty type, max iterations (epochs), and l1 ratio in the case of elasticnet being the penalty. Ultimately, the parameters of the female Logistic Regression model were C = 0.1, l1 ratio = 0.25, max iteration = 100, penalty = elasticnet, with a cross validation accuracy of 87%. The resulting parameters for the male model were C = 0.001, max iteration = 100, and penalty = l2, with an accuracy of 82%.

For the task of predicting the continuous variable of stroke risk percentage, a Random Forest (RF) Regressor was used, as one for each gender. This model works by creating several decision trees in the training process and outputting the mean prediction of each tree. RF Regressor is the best option for this task because it handles non-linear relationships and data with high dimensionality. This model was also imported from scikit-learn.

Hyperparameter tuning for the RF Regressor models also entailed using a pipeline implementing RF Regressor and Standardization using Standard Scaler. This pipeline did not use Principal Component Analysis (PCA) because the model already has dimensionality reduction properties. Hence, the result of adding PCA was the same as not using the technique. The tuning was done using grid search cross-validation with cv equal to 10, and the hyperparameters were based on Negative Mean Square Error (N-MSE). The parameters tested in this process were a number of estimators, max depth, minimum sample split, and minimum sample leaf. The resulting parameters from hyperparameter tuning for the female model were n estimators = 200, max depth = 10, min samples split = 10, and min samples leaf = 4. The Mean Squared Error (MSE) and R squared value taken from N-MSE were 165.1 and 0.808. For the male model, they were n estimators = 200, min samples split = 2, max depth = 5, and min samples leaf = 4. The MSE of the model was 241.9, and the R^2 value was 0.738.

## Evaluation of Results
In comparison, both female-based models outperform both male-based models. So, the male predictors are more likely to misrepresent authentic relationships. These results include the F1 Score and accuracy used to evaluate the accuracy of both Logistic Regression models and MSE and R^2 used to evaluate the performance of the RF Regressor models. The resulting F1 Score and accuracy percentage of the female Logistic Regression model with the task of classifying the discrete integer at risk target were 0.800 and 87.5%. In contrast, the male model's F1 Score and accuracy percentage were 0.751 and 81.8%. For the RF Regressor models, the resulting MSE and R^2 values for the predictor model evaluating the continuous variable of stroke risk percentage for the female model were 165.11 and 0.808. As for the male MSE and R^2 values, they were 241.92 and 0.738. For these scores, the higher the F1 score and accuracy, the better the model's performance for predicting outcomes. As for MSE and R^2, the lower the MSE, the lower the error in predictors, and the lower the R^2, the lower the performance because R^2 evaluates the proportion of variance.

So, the best models from each model discussed were the female RF Regressor model and the female Logistic Regression model, with the best predictor for women being the RF Regressor and the best predictor out of the male models being the Logistic Regression model. Overall, the male predictors fell short of expectations, so adequate comparisons between anxiety-induced stroke risk for men can loosely be compared to the female models. Since the RF Regressor demonstrates better predictors of stroke risk outcomes for women, it will be used to evaluate the rest of the data set.
